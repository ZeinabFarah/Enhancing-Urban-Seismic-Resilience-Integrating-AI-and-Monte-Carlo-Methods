{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXfk/TbLTzlCXm/2GcwhCM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7sOuSczbHrA","executionInfo":{"status":"ok","timestamp":1715516230279,"user_tz":240,"elapsed":17481,"user":{"displayName":"Zeinab Farahmandfar","userId":"16605779484918920271"}},"outputId":"29952a2d-5dc4-4424-d52b-007cb37c7a96"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVBCAJlGbADT","executionInfo":{"status":"ok","timestamp":1715516231025,"user_tz":240,"elapsed":749,"user":{"displayName":"Zeinab Farahmandfar","userId":"16605779484918920271"}},"outputId":"7a69a137-333e-4fd2-ffeb-962fd2ade07e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Colab Notebooks/Enhancing Urban Seismic Resilience: Integrating AI and Monte Carlo Methods for Real-Time Hazard Prediction/modules/initial_setup.py\n"]}],"source":["%%writefile '/content/drive/MyDrive/Colab Notebooks/Enhancing Urban Seismic Resilience: Integrating AI and Monte Carlo Methods for Real-Time Hazard Prediction/modules/initial_setup.py'\n","\n","import pandas as pd\n","import json\n","\n","class InitialSetup:\n","    def __init__(self, source_data_path, site_data_path):\n","        \"\"\"\n","        Initializes the InitialSetup with paths to site and source data files.\n","\n","        Parameters:\n","        -----------\n","        source_data_path : str\n","            The file path to the JSON file containing source data.\n","        site_data_path : str\n","            The file path to the shape file containing site data.\n","        id_column_name : str\n","            The name of the column in the shape file that contains the site identifiers.\n","\n","        Attributes:\n","        -----------\n","        site_data : pandas.DataFrame\n","            A dataframe containing the processed site data.\n","        num_sites : int\n","            The number of site locations.\n","        source_data : dict\n","            A dictionary containing the processed source data.\n","        num_sources : int\n","            The number of earthquake sources.\n","        \"\"\"\n","        self.site_data, self.num_sites = self.read_site_data(site_data_path)\n","        self.source_data, self.num_sources = self.read_source_data(source_data_path)\n","        self.extract_source_data()\n","        self.extract_site_data()\n","\n","    def read_site_data(self, file_path):\n","        \"\"\"\n","        Reads a CSV file and processes it to ensure it has the required columns.\n","        Also calculates the number of sites (rows) in the data.\n","\n","        Parameters:\n","        -----------\n","        file_path (str):\n","            Path to the CSV file.\n","\n","        Returns:\n","        -----------\n","        site_data (pandas dataframe):\n","            A data frame with the processed data.\n","        num_sites (int):\n","            Number of sites (rows) in the DataFrame.\n","        \"\"\"\n","        # Read the CSV file\n","        try:\n","            site_data = pd.read_csv(file_path)\n","        except Exception as e:\n","            raise IOError(f\"Error reading the file: {e}\")\n","\n","        # Validate the columns\n","        required_columns = ['id', 'latitude', 'longitude', 'depth', 'vs30', 'condition']\n","        if not all(column in site_data.columns for column in required_columns):\n","            raise ValueError(f\"The CSV file must contain the following columns: {required_columns}\")\n","\n","        # Calculate the number of sites\n","        num_sites = site_data.shape[0]\n","\n","        return site_data, num_sites\n","\n","    def read_source_data(self, file_path):\n","        \"\"\"\n","        Reads earthquake source characteristics from a JSON file.\n","\n","        Parameters:\n","        -----------\n","        file_path (str):\n","            Path to the JSON file.\n","\n","        Returns:\n","        -----------\n","        source_data (dict):\n","            Dictionary containing earthquake source data.\n","        num_sources (int):\n","            Number of earthquake sources in the data.\n","        \"\"\"\n","        try:\n","            with open(file_path, 'r') as file:\n","                source_data = json.load(file)\n","\n","            num_sources = len(source_data)\n","            return source_data, num_sources\n","\n","        except Exception as e:\n","            raise IOError(f\"Error reading the file: {e}\")\n","\n","    def extract_source_data(self):\n","        \"\"\"Extracts parameters from each source in source_data.\"\"\"\n","        self.source_m_min = {name: data[\"M_min\"] for name, data in self.source_data.items()}\n","        self.source_m_max = {name: data[\"M_max\"] for name, data in self.source_data.items()}\n","        self.source_nu = {name: data[\"nu\"] for name, data in self.source_data.items()}\n","        self.source_lat = {name: data[\"lat\"] for name, data in self.source_data.items()}\n","        self.source_lon = {name: data[\"lon\"] for name, data in self.source_data.items()}\n","        self.source_depth = {name: data[\"depth\"] for name, data in self.source_data.items()}\n","        self.source_strike = {name: data[\"strike\"] for name, data in self.source_data.items()}\n","        self.source_dip = {name: data[\"dip\"] for name, data in self.source_data.items()}\n","        self.source_mechanism = {name: data[\"mechanism\"] for name, data in self.source_data.items()}\n","        self.source_event_type = {name: data[\"event_type\"] for name, data in self.source_data.items()}\n","\n","        # Determining the overall min and max magnitudes\n","        self.m_min_min = max(self.source_m_min.values())\n","        self.m_max_max = min(self.source_m_max.values())\n","\n","    def extract_site_data(self):\n","        \"\"\"Extracts parameters from each site in site_data\"\"\"\n","        self.site_id = self.site_data['id']\n","        self.site_lat = self.site_data['latitude']\n","        self.site_lon = self.site_data['longitude']\n","        self.site_depth = self.site_data['depth']\n","        self.site_vs30 = self.site_data['vs30']\n","        self.site_condition = self.site_data['condition']"]}]}